{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d2958e-3d89-4e23-b195-b3db779baaae",
   "metadata": {},
   "source": [
    "# Hail\n",
    "####  Hail is a Python library that enables scalable analysis of structured data, with specialized support for accessing, transforming, and analyzing massive genomic datasets\n",
    "\n",
    "### Main Hail Objects\n",
    "\n",
    "Hail provides a set of powerful, distributed data structures designed for scalable genomic analysis. The main Hail objects are:\n",
    "\n",
    "---\n",
    "\n",
    "- **[MatrixTable](https://hail.is/docs/0.2/overview/matrix_table.html)**  \n",
    "  The `MatrixTable` is the **primary data structure** for genomic datasets. It can import genomic data from many formats, such as VCF.  \n",
    "  The `MatrixTable` builds upon the Hail `Table` and is conceptually similar to a two-dimensional matrix with two tables attached to it. It comprises four components:\n",
    "\n",
    "  - **Row fields**: A set of fields that are constant for every column. These typically represent **variants** (e.g., positions in the genome).\n",
    "  - **Column fields**: A set of fields that are constant for every row. These typically represent **samples**.\n",
    "  - **Entry fields**: A **two-dimensional matrix**, where each entry is **indexed by row key(s) and column key(s)** and stores per-variant, per-sample data (e.g., genotypes).\n",
    "  - **Global fields**: A structured set of information associated with the entire dataset.\n",
    "  \n",
    "  The `MatrixTable` supports rich annotations for each of its fields and is typically used for:\n",
    "\n",
    "  - Quality control (QC)  \n",
    "  - Variant filtering and annotation  \n",
    "  - GWAS\n",
    "\n",
    "---\n",
    "\n",
    "- **[Table](https://hail.is/docs/0.2/hail.Table.html#hail.Table)**  \n",
    "  A `Table` is a **general-purpose distributed table**, similar to a Pandas DataFrame, but designed to scale across clusters (like Spark DataFrames).  \n",
    "  It represents one axis of a `MatrixTable` or standalone data.  \n",
    "\n",
    "  A Hail `Table` consists of:\n",
    "\n",
    "  - **Row fields**: Structured data stored in the table rows (i.e., columns in tabular format).\n",
    "  - **Global fields**: A structured set of information associated with the entire table.  \n",
    "\n",
    "  Tables are typically used to store:\n",
    "\n",
    "  - Phenotype or sample metadata  \n",
    "  - Variant annotation databases  \n",
    "  - Aggregation results\n",
    "\n",
    "---\n",
    "\n",
    "- **[Expression](https://hail.is/docs/0.2/overview/expressions.html)**  \n",
    "  Hail uses expression objects to represent different types of data and their operations.  \n",
    "  Hail expressions are **lazily evaluated**, meaning they define computations without executing them immediately. Evaluation occurs during pipeline execution or when triggered by an **action**.\n",
    "\n",
    "  Each Hail data type has a corresponding expression class.  \n",
    "  For example:\n",
    "\n",
    "  - `Int32Expression` represents a 32-bit integer value.  \n",
    "  - `BooleanExpression` represents a boolean value (`True` or `False`).\n",
    "\n",
    "  Expressions are used to define computations, filters, and annotations. They are evaluated by Hail’s backend during execution of **actions**, such as:\n",
    "\n",
    "  - `show()`  \n",
    "  - `take()`  \n",
    "  - `collect()`  \n",
    "  - `eval()`\n",
    "\n",
    "---\n",
    "\n",
    "- **Keys**\n",
    "\n",
    "  Every Hail `Table` has a **key** that determines the **ordering of rows** and enables **joins or annotations** with other tables.\n",
    "\n",
    "  `MatrixTable` objects have **two keys**:\n",
    "\n",
    "  - **Row key**: Indexes the row fields (e.g., variants).\n",
    "  - **Column key**: Indexes the column fields (e.g., samples).\n",
    "  - **Entry fields**: Indexed by the combination of both the **row key** and **column key**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe61aa5-8366-4374-b7e8-dce22992745c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8381a5-82af-415e-96db-6ce67a947290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import hail as hl\n",
    "\n",
    "from hail.plot import show\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "hl.plot.output_notebook()\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e50f-9502-453d-85ba-3b38bbae1e3a",
   "metadata": {},
   "source": [
    "#### Start an [Apache Spark](https://en.wikipedia.org/wiki/Apache_Spark) instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebe51c-4ab9-451e-a32f-226e5e477c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = f\"logs/hail-{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}.log\"\n",
    "# run spark\n",
    "spark_conf = SparkConf().setAppName(\"hail-test\")\n",
    "# .setMaster(\"spark://spark-master:7077\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://lifemap-minio:9000/\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.access.key\", \"root\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"passpass\" )\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.connection.maximum\", 1024);\n",
    "spark_conf.set(\"spark.hadoop.fs.s3a.threads.max\", 1024);\n",
    "spark_conf.set(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "try:\n",
    "    sc = SparkContext(conf=spark_conf)\n",
    "except:\n",
    "    print (\"Spark session already up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d6260-bf6d-45ba-a0ce-b58c688276d1",
   "metadata": {},
   "source": [
    "#### Create bucket on [Minio](https://min.io/) if it does not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5137a-45aa-4d0d-8b42-df50d3c97b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# S3 configuration\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=\"http://lifemap-minio:9000\",\n",
    "    aws_access_key_id=\"root\",\n",
    "    aws_secret_access_key=\"passpass\",\n",
    ")\n",
    "\n",
    "bucket_name = \"data-hail\"\n",
    "\n",
    "# Check if the bucket exists, if not, create it\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' exists.\")\n",
    "except Exception:\n",
    "    # If the bucket does not exist, create it\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7919cb2-8906-44d2-8750-7c359ce58798",
   "metadata": {},
   "source": [
    "### [Hail](https://hail.is/) initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113ae2b-9754-4e8b-b2d3-2839ac142b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.init(sc=sc, log=log_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e3c63-e86d-46af-97c5-8651867fbc9c",
   "metadata": {},
   "source": [
    "#### Set filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60272387-1744-4e83-a428-da2df979f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VCF\n",
    "vcf_fn = 'data/1kg.vcf'\n",
    "#vcf_fn = 'data/hs1.vcf'\n",
    "\n",
    "## Annotation file\n",
    "annotations_fn = 'data/1kg_annotations.txt'\n",
    "## Matrix table\n",
    "mt_fn = 's3://data-hail/1kg.mt'\n",
    "\n",
    "print (f\"VCF fn: {vcf_fn}\")\n",
    "print (f\"Annotation file fn: {annotations_fn}\")\n",
    "print (f\"Matrix table fn: {mt_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f6ab9-715c-4f47-a3bf-cf52e5912bbe",
   "metadata": {},
   "source": [
    "#### Reading vcf with Pandas (N/A if the vcf is stored on s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9a733-da94-4149-b507-c636ec4087e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_pd = None\n",
    "if \"s3://\" not in vcf_fn: \n",
    "    vcf_pd = pd.read_csv(vcf_fn, sep=\"\\t\", header=109, low_memory=False)\n",
    "vcf_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d74bab-ae72-4ebb-a48c-87577ba8b411",
   "metadata": {},
   "source": [
    "### Import VCF to Hail Matrix Table\n",
    "To work with genomic data stored in a **VCF**, we need to first import and converted it into a **Hail Matrix Table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc132d8-384b-49ab-aaf6-4bd5228a0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read a vcf file, convert to a matrix table and save it.\n",
    "mt = hl.import_vcf(vcf_fn, reference_genome=\"GRCh37\") \n",
    "mt.write(mt_fn, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df411fdb-5ff2-453a-82e1-17b279fafefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the matrix table from the file and assign it to the mt vaiable\n",
    "mt = hl.read_matrix_table(mt_fn)\n",
    "\n",
    "## Assign MatrixTable fields to Hail tables\n",
    "row_table = mt.rows() # Returns the row field table\n",
    "col_table = mt.cols() # Returns the col field table\n",
    "entry_fields = mt.entries() # Returns the entry field matrix in coordinate table form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96b42d-4377-414e-a2bb-43b45db683cb",
   "metadata": {},
   "source": [
    "![alt text](immagini/vcf_matrix_table.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50194496-b92f-41a7-a0d6-cf1735105719",
   "metadata": {},
   "source": [
    "#### Counting samples and variant: MatrixTable `count_rows` and `count_cols` methods and Table `count` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5072c-79d7-4b6c-972c-b3f6fb56c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counts of samples and variants\n",
    "n_variants = mt.count_rows() \n",
    "n_samples = mt.count_cols()\n",
    "\n",
    "print (f\"\\n\\nThe dataset has {n_variants} variants and {n_samples} samples\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29b54c-ed3d-4c79-b326-c052813b67ab",
   "metadata": {},
   "source": [
    "##### Show a description of the MatrixTable components: the `describe` and `show` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea950cd3-4f54-4278-83f3-ad434e0b5adb",
   "metadata": {},
   "source": [
    "##### MatrixTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcab9e-7302-49ee-962a-c58ca3d48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5c7fd-1b4b-4281-a2a2-c7f5b7e8143d",
   "metadata": {},
   "source": [
    "##### Row table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee5ad7-e653-4265-a1d3-988937edda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccae31-81b3-4dd4-afd8-de014d7a91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be07b06-9072-47e1-a4f0-a487595f4a5e",
   "metadata": {},
   "source": [
    "##### Column table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15386e64-1ca6-49fd-ae5c-98535eca8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55519c09-f11e-4099-afe7-63cc106f93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0044105-9171-45a4-88f2-bbb18be0626b",
   "metadata": {},
   "source": [
    "#### Entry fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bab8b4-1ec6-4caa-8f91-8f966b0a51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_fields.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228331a4-92be-4bd0-884d-efda2885425f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entry_fields.select(entry_fields.GT, entry_fields.AD, entry_fields.DP, entry_fields.GQ, entry_fields.PL).show(n_samples + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9b4f8-16ba-43a9-b9ab-1029c251425e",
   "metadata": {},
   "source": [
    "#### Show attributes of entry fields. An example with the genotype field.\n",
    " - `entry` attribute\n",
    " - **Call** `phased` attributes\n",
    " - **Call** `summarize` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304fb17-61dd-47cc-8f96-15d45eb9d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attributes of entry fields\n",
    "entry_structure = mt.entry\n",
    "\n",
    "# The StructExpression\n",
    "print (entry_structure)\n",
    "\n",
    "# To show only entry field names\n",
    "print (list(entry_structure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97e2b8-f02a-45b0-8540-24af536c47a8",
   "metadata": {},
   "source": [
    "To look at the first few genotype calls, we can use entries along with select and take. The **`take` method collects the first n rows into a Python list**. Alternatively, we can use the `show` method, which prints the first n rows to the console in a table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d392ae7-ef97-422d-a78e-aa130cd2e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_expr = mt.GT # Takes the GT entry field for all samples \n",
    "gt_expr.phased.show(5) # Show the phased attribute of the GT field (It is False for not phased haplotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1257c22-ea80-45b6-a915-65dff49937c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_expr.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abb72b-1c45-4d19-8799-6cc486304fe6",
   "metadata": {},
   "source": [
    "##### Global values.\n",
    "Common values of the matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc999fe-c9cc-400b-9d1d-4f3b3b8aa488",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.globals_table().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44cbb8-dcab-4ebb-80f2-b9e697c0e980",
   "metadata": {},
   "source": [
    "### How to access and insert data into a Hail Table using the [`select`](https://hail.is/docs/0.2/hail.Table.html#hail.Table.select) and [`annotate`](https://hail.is/docs/0.2/hail.Table.html#hail.Table.annotate) methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b6deb-8044-46dc-834f-f9b318358e8d",
   "metadata": {},
   "source": [
    "We can use the Hail Table `select` method to extract specific fields from a table.\n",
    "\n",
    "The `select` method takes either a string referring to a field name in the table or a Hail expression. If no arguments are provided, only the row key fields (`locus` and `alleles`) are retained.\n",
    "\n",
    "The `select` method can also be used to add or transform fields, but the resulting table will include **only** the specified fields and any new fields defined in the expression; all other fields will be removed.\n",
    "\n",
    "In contrast, the `annotate` method adds or modifies fields while preserving the entire original table structure. It returns the full table with the new or updated fields included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085591d-ca43-44a2-9aa2-cb3bd35c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4502bc2-e4c1-42ae-b114-bde9af9068c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(row_table.select().show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801acb1f-33bb-4771-bf9f-ea88ce399783",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select a field of the row table: Simple field and nested field\n",
    "row_table.select(\"qual\", row_table.info.AC).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760aec6-f024-4abc-8052-6cd3009011c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding a new column to the table. The not listed columns will be deleted in the new table\n",
    "row_table.select(row_table.qual, new_col= row_table.qual * 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d24372-3a72-4cc7-9c94-c63d69ddfe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding a new column to the table. The not listed columns will not be deleted in the new table\n",
    "row_table.annotate(new_col= row_table.qual * 10).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33519d4-ca90-4d42-9239-b0923edfba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.rows().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce44ada-294c-48cb-9382-494bfd78b254",
   "metadata": {},
   "source": [
    "### Annotating a MatrixTable Using a Sample Metadata Table\n",
    "\n",
    "Metadata about samples—such as phenotypes or geographic origin—is often stored in a separate text file, which can be imported into Hail as a `Table`.\n",
    "\n",
    "A Hail `MatrixTable` can have any number of **row fields** and **column fields** for storing metadata associated with each row (e.g., variants) and column (e.g., samples). Annotations are a critical part of genetic studies. **Column fields** are used to store information such as sample phenotypes, ancestry, sex, and covariates. **Row fields** can be used to store attributes like gene membership or predicted functional impact, often used in QC or analysis.\n",
    "\n",
    "In this example, we’ll use a text file to annotate the columns of a `MatrixTable`.\n",
    "\n",
    "The annotation file includes:\n",
    "- Sample ID\n",
    "- Population and super-population labels\n",
    "- Sample sex\n",
    "- Two simulated phenotypes: one binary (Purple Hair), one continuous (Caffeine Consumption)\n",
    "\n",
    "This file can be imported using Hail’s `import_table` function, which returns a **`Table` object**. This object behaves similarly to a Pandas or R DataFrame but is distributed across Spark and not limited by the memory of a single machine. Like the `MatrixTable`, a `Table` is **immutable**.   \n",
    "To inspect or interact with the data locally in Python, you can use the `.take()` method or convert the table to a Pandas DataFrame using `.to_pandas()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1030732-5872-4969-ba6a-17032aea41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_table = (hl.import_table(annotations_fn, impute=True).key_by('Sample')) #  impute=True, guess field types from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5dc3f-7ccc-4f4d-b63c-124fb6942d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18151a12-828d-4575-ada3-4e04900dc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79bb24-f69c-482f-baf4-a9594e8dee46",
   "metadata": {},
   "source": [
    "#### Query functions for gathering statistics: The Table `aggregate` method and Hail `aggregators` (see [Aggregation](https://hail.is/docs/0.2/guides/agg.html) and [Aggregators](https://hail.is/docs/0.2/aggregators.html#sec-aggregators) for details)\n",
    "\n",
    "Hail provides a number of useful query functions for gathering statistics from your dataset. These functions take **Hail aggregate expressions** as arguments.\n",
    "\n",
    "For example, [`counter`](https://hail.is/docs/0.2/aggregators.html#hail.expr.aggregators.counter) is an aggregation function that counts the number of occurrences of each unique element. You can use this to compute the population distribution by passing in a Hail expression referencing the field you'd like to count.\n",
    "\n",
    "The `aggregate` method is used to perform aggregation across rows in a `Table`. Aggregator functions like `counter`, `stats`, and others specify what statistics to compute and how to compute them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84858687-a300-4a2b-ad16-025b2d2d58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Population distribution\n",
    "## Here counter counts unique geographycal origin label\n",
    "aggregate_expression = hl.agg.counter(annotation_table.SuperPopulation)\n",
    "print (aggregate_expression)\n",
    "pprint(annotation_table.aggregate(aggregate_expression))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a0664-a1aa-466e-9539-f81faf49796e",
   "metadata": {},
   "source": [
    "[`stats`](https://hail.is/docs/0.2/aggregators.html#hail.expr.aggregators.stats) is an aggregation function that produces some useful statistics about numeric collections. We can use this to see the distribution of the CaffeineConsumption phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec22783-40dc-4a7c-ba9e-6ed59ae15900",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stats perform some statistics on the specified field\n",
    "## Here take stats of the caffeine consumption\n",
    "\n",
    "aggregate_expression = hl.agg.stats(annotation_table.CaffeineConsumption)\n",
    "pprint(annotation_table.aggregate(aggregate_expression))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14635f-7e78-43a1-93b0-bfc34ef750b5",
   "metadata": {},
   "source": [
    "#### Grouping to Summarize Information Within Superpopulations: The Table [`group_by`](https://hail.is/docs/0.2/hail.Table.html#hail.Table.group_by) Method\n",
    "\n",
    "The Table `group_by` method allows you to apply aggregation functions to groups of rows based on specified keys. When working with a grouped table, the [`aggregate`](https://hail.is/docs/0.2/hail.GroupedTable.html#hail.GroupedTable.aggregate) method behaves slightly differently from `Table.aggregate`: it requires a *name expression* rather than a simple expression, and it returns a new table rather than a single result (such as a number or a struct). The *name expression* means that each aggregation must be assigned to a field name, which becomes a column in the resulting aggregated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ee1b8-b6d2-4895-b2a3-0dac8f9b56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = annotation_table.group_by('SuperPopulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800eda2-67ac-4d6c-b565-84160726fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp.aggregate(cnt=hl.agg.counter(annotation_table.isFemale)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fcadb-dc3c-4ea5-bec1-c8c04f80ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp.aggregate(stats=hl.agg.stats(annotation_table.CaffeineConsumption)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d81a5c-8953-4c6f-b114-b22d14566657",
   "metadata": {},
   "source": [
    "#### Annotate the MatrixTable column fields: The MatrixTable [`annotate_cols`](https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_cols) method\n",
    "\n",
    "Using the `annotate_cols` method is possible to join the annotation table with the MatrixTable containing the dataset.\n",
    "First, we’ll print the existing column schema using `col`. MatrixTable [`col`](https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.col) is an attribute that return struct expression of all column-indexed fields, including keys.\n",
    "It is different from the [`cols()`](https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.cols) method that returns a table with all column fields in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d701a5-7147-4063-936b-ed7fcf4aea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column table before adding per sample annotation:\n",
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a250f-55f2-48ba-b676-c9977852f75f",
   "metadata": {},
   "source": [
    "Setting the sample IDs as the key of the annotation table allows you to index sample information using the sample IDs from the `mt.s` column field of the `MatrixTable`. The indexed data can then be used to annotate the `MatrixTable`, adding a `pheno` field to its column annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60fff5-90be-438e-bd59-f9bee1b7eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(pheno = annotation_table[mt.s])\n",
    "\n",
    "# After the annotation the columns has a new field pheno,\n",
    "# a struct that contains sample metadata\n",
    "\n",
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd03a59-2f7b-41f5-a530-ed96fd714c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Metadata table samples: {annotation_table.count()}\")\n",
    "print(f\"Matrix table samples: {mt.cols().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a631c-b39c-479d-bf0a-a8c23463594f",
   "metadata": {},
   "source": [
    "Since there are fewer samples in our dataset than in the full thousand genomes cohort, we need to look at annotations on the dataset. We can use [`aggregate_cols`](https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.aggregate_cols) to get the metrics for only the samples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557a494-4867-4f1c-9dd5-fa33ad703900",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.aggregate_cols(hl.agg.counter(mt.pheno.SuperPopulation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd510b-667e-4072-b894-77c412d8004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(mt.aggregate_cols(hl.agg.stats(mt.pheno.CaffeineConsumption)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a051048-2e67-43c9-bbfb-80b99bcf7aed",
   "metadata": {},
   "source": [
    "**The same Python, R, and Unix tools could do this work as well, but we’re starting to hit a wall - the latest gnomAD release publishes about 250 million variants, and that won’t fit in memory on a single computer.**\n",
    "\n",
    "What about genotypes? Hail can query the collection of all genotypes in the dataset, and this is getting large even for our tiny dataset. Our 284 samples and 10,000 variants produce 10 million unique genotypes. The gnomAD dataset has about 5 trillion unique genotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a06451f-ab4c-441e-8389-7d06ba547b81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c648e-feb0-4405-a9d8-ab7a407645cd",
   "metadata": {},
   "source": [
    "### Quality Control and Data Filtering\n",
    "\n",
    "Quality control (QC) is an iterative process that varies across projects—there is no simple, “push-button” solution. However, through open science and collaboration, the community has established a set of best practices to guide QC decisions.\n",
    "\n",
    "Effective QC depends on a deep understanding of the dataset’s properties. Hail supports this by providing the [`sample_qc`](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.sample_qc) and [`variant_qc`](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc) functions, which compute useful summary metrics. These metrics are stored in column fields (for samples) and row fields (for variants), respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e186384-0bfc-42de-a94e-1fd37a2413e8",
   "metadata": {},
   "source": [
    "#### Sample QC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5425e98-0d63-48b4-b2ef-6382931bf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255d1b0-87ca-4d1e-a213-0cc451dcf8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_qc is a hail genetic method to compute per-sample metrics useful for quality control.\n",
    "\n",
    "mt = hl.sample_qc(mt)\n",
    "\n",
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da758a86-41df-482d-bc21-26d963fe5b5b",
   "metadata": {},
   "source": [
    "##### Hail plotting functions\n",
    "Hail plotting functions allow Hail fields as arguments.  \n",
    "If the range and bins arguments are not set, this function will compute the range based on minimum and maximum values of the field and use the default 50 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e458ef-a374-4037-ba8c-e583df52910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotting the QC metrics is a good place to start.\n",
    "\n",
    "## Call rate\n",
    "p = hl.plot.histogram(mt.sample_qc.call_rate, range=(.88,1), legend='Call Rate')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb8e67-cb96-4042-9b60-e52c8fb8b15c",
   "metadata": {},
   "source": [
    "##### Removing samples: `filter_cols` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8a553-09e9-49b3-b2da-acdbc107228c",
   "metadata": {},
   "source": [
    "Removing outliers from the dataset will generally improve association results. We can make arbitrary cutoffs and use them to filter.\n",
    "Using matrix table [`filter_cols`](https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.filter_cols) method it is possible to **create a new matrix table considering samples with the DP mean >= 4 and a call rate >= 0.97**. Samples that don't satisfy these criteria are removed.\n",
    "The filtering method does not perform in-place filtering, so the result must be assigned to a variable for the changes to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd268ee8-7c41-4fbc-8b3e-bf7f76ab96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking corralations between the mean value of dp and the call rate\n",
    "p = hl.plot.scatter(mt.sample_qc.dp_stats.mean, mt.sample_qc.call_rate, xlabel='Mean DP', ylabel='Call Rate')\n",
    "p.line([2,22], [0.97,0.97], color='red', line_width=2)\n",
    "p.line([4,4], [0.878,1.0], color='red', line_width=2)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90eebb-0e0d-4cfc-bfbf-33ad0e79e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\n",
    "print('After filter, %d/284 samples remain.' % mt.count_cols())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd59a7b-2552-4748-98bd-6b353e0279d8",
   "metadata": {},
   "source": [
    "##### Removing genotypes: `filter_entries`\n",
    "Next is genotype QC. It’s a good idea to filter out genotypes where the reads aren’t where they should be: if we find a genotype called homozygous reference with >10% alternate reads, a genotype called homozygous alternate with >10% reference reads, or a genotype called heterozygote without a ref / alt balance near 1:1, it is likely to be an error.\n",
    "\n",
    "In a low-depth dataset like 1KG, it is hard to detect bad genotypes using this metric, since a read ratio of 1 alt to 10 reference can easily be explained by binomial sampling. However, in a high-depth dataset, a read ratio of 10:100 is a sure cause for concern!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841dac1-4339-42b6-8c3d-0c50fff2db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = mt.AD[1] / hl.sum(mt.AD)\n",
    "\n",
    "filter_condition_ab = ((mt.GT.is_hom_ref() & (ab <= 0.1)) |\n",
    "                        (mt.GT.is_het() & (ab >= 0.25) & (ab <= 0.75)) |\n",
    "                        (mt.GT.is_hom_var() & (ab >= 0.9)))\n",
    "\n",
    "fraction_filtered = mt.aggregate_entries(hl.agg.fraction(~filter_condition_ab))\n",
    "print(f'Filtering {fraction_filtered * 100:.2f}% entries out of downstream analysis.')\n",
    "mt = mt.filter_entries(filter_condition_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d39b72-23e3-437d-8876-3fded800523a",
   "metadata": {},
   "source": [
    "##### Variant QC function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2317313-07b7-419d-88e0-58bda02c2825",
   "metadata": {},
   "source": [
    "Variant QC computes per per-variant metric useful for quality control. It is a bit more of the same of sample_qc: we can use the [`variant_qc`](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc) function to produce a variety of useful statistics, plot them, and then filter. This is made at row level beacause they are stats on variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86045ff2-dd0a-4270-91d3-b0582032415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.row.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bb5d8-40bf-41fa-82d6-e8fb6e124b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.variant_qc(mt)\n",
    "mt.row.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9a82b-2650-4953-9240-4662e8f1dd79",
   "metadata": {},
   "source": [
    "##### Removing variants: `filter_rows`\n",
    "Restrict to variants that are:\n",
    "- common (we’ll use a cutoff of 1%)\n",
    "- not so far from Hardy-Weinberg equilibrium as to suggest sequencing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5594f8-e32d-43fe-87b3-b7feaf898984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Samples: %d  Variants: %d' % (mt.count_cols(), mt.count_rows()))\n",
    "mt = mt.filter_rows(mt.variant_qc.AF[1] > 0.01) # It takes variants for which the alternate allele has a frequency larger than 1%\n",
    "print('Samples: %d  Variants: %d' % (mt.count_cols(), mt.count_rows()))\n",
    "\n",
    "mt = mt.filter_rows(mt.variant_qc.p_value_hwe > 1e-6) # Hardy-Weinberg equilibrium pvalue cut-off\n",
    "print('Samples: %d  Variants: %d' % (mt.count_cols(), mt.count_rows()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3fb18-bc48-408a-840a-0c61f7b8dded",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315f777-bc1b-452b-858c-15a700d5e189",
   "metadata": {},
   "source": [
    "## GWAS with a quantitative phenotype\n",
    "\n",
    "In Hail, the association tests accept column fields for the sample phenotype and covariates. Since we’ve already got our phenotype of interest (caffeine consumption) in the dataset, we are good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd29f27-6114-47c8-8843-a6b67bc5d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption,\n",
    "                                 x=mt.GT.n_alt_alleles(),\n",
    "                                 covariates=[1.0])\n",
    "gwas.row.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a84fa-8071-41c6-b0f4-4b82c02b8199",
   "metadata": {},
   "source": [
    "Looking at the bottom of the above printout, you can see the linear regression adds new row fields for the beta, standard error, t-statistic, and p-value.\n",
    "\n",
    "Hail makes it easy to visualize results! Let’s make a Manhattan plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70e1d8-7857-499e-bef3-0ed8968beffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5873b-cd39-4fc2-9b51-09fa09e924df",
   "metadata": {},
   "source": [
    "Let’s check whether our GWAS was well controlled using a Q-Q (quantile-quantile) plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ca913-3b03-4fd1-a0df-4f2a62692017",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a0b77-dfa6-4fac-b34c-e4907fb03893",
   "metadata": {},
   "source": [
    "## Confounded!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a4335-b9ae-417a-a4b4-ed1f4c1d6514",
   "metadata": {},
   "source": [
    "The observed p-values deviate from the expected distribution immediately. Either every SNP in our dataset is causally linked to caffeine consumption (which is highly unlikely), or there's an underlying confounder.\n",
    "\n",
    "In fact, the phenotype was simulated using sample ancestry (in addition to a specific locus associated with caffeine consumption). This results in a **stratified phenotype distribution**. To correct for this, we need to include ancestry as a covariate in our regression model.\n",
    "\n",
    "The `linear_regression_rows` function allows us to include column fields as covariates. Although we’ve already annotated samples with reported ancestry, such labels can be unreliable due to human error. Genomes, however, don't suffer from this issue. Rather than using reported ancestry, we’ll use **genetic ancestry** by incorporating the computed principal components (PCs) into our model.\n",
    "\n",
    "The `pca` function outputs eigenvalues as a list and sample PCs as a `Table`; it can also generate variant loadings if requested. The `hwe_normalized_pca` function offers similar outputs, but uses Hardy-Weinberg Equilibrium (HWE)-normalized genotypes for the PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b55f0-b8a8-490e-9399-b5d6bc66cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.GT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f1140-1810-4256-8051-ae3f84cba377",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e7012-b34a-4bfa-b40c-a74d5a6c1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468cb35-c59d-4390-bc8f-bfc4dba6a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.show(5, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21007ea8-3f18-40c2-81b5-913fa1e3ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccd0ff-fcf6-4629-bd89-dfc2cddf8beb",
   "metadata": {},
   "source": [
    "Since we now have the principal components for each sample, we can annotate them to the MatrixTable's column fields and and plot them to examine how well they align with the major human populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0083fa0e-a2e6-4dc2-aa87-795728976dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(scores = pcs[mt.s].scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1de97-4261-401e-9840-6639ee8d823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.scatter(mt.scores[0],\n",
    "                    mt.scores[1],\n",
    "                    label=mt.pheno.SuperPopulation,\n",
    "                    title='PCA', xlabel='PC1', ylabel='PC2')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770b933-7160-4c0f-9d1d-e7f37c038758",
   "metadata": {},
   "source": [
    "Now we can rerun our linear regression, controlling for sample sex and the first few principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1148a65-caf2-4481-951b-5651da095d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas = hl.linear_regression_rows(\n",
    "    y=mt.pheno.CaffeineConsumption,\n",
    "    x=mt.GT.n_alt_alleles(),\n",
    "    covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac96bb-3333-412c-b5fd-d25ea1e70df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c00cd-3a5c-4f19-86c9-a8f93f4d59c4",
   "metadata": {},
   "source": [
    "Q-Q plot and Manhattan plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46816505-170a-4305-9538-9e12b0d7faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5fb11-a4bc-4cd1-bbf9-6e143718ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef52005-4d69-4481-a93a-e52bdc11663f",
   "metadata": {},
   "source": [
    "#### How to save Table and MatrixTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6016a7-c6e7-4896-89f2-ee4d99da0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_ht_fn = 's3://data-hail/gwas_results.ht'\n",
    "gwas.write(gwas_ht_fn, overwrite=True)\n",
    "    \n",
    "mt_out_fn = 's3://data-hail/1kg_after_gwas.mt'\n",
    "mt.write(mt_out_fn, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
